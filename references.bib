@article{Williams1992,
  title = {Simple statistical gradient-following algorithms for connectionist reinforcement learning},
  volume = {8},
  ISSN = {1573-0565},
  url = {http://dx.doi.org/10.1007/BF00992696},
  DOI = {10.1007/bf00992696},
  number = {3–4},
  journal = {Machine Learning},
  publisher = {Springer Science and Business Media LLC},
  author = {Williams,  Ronald J.},
  year = {1992},
  month = may,
  pages = {229–256}
}

@misc{GymnasiumCartPole,
	author = {},
	title = {{G}ymnasium {D}ocumentation -- {C}art {P}ole},
	howpublished = {\url{https://gymnasium.farama.org/environments/classic_control/cart_pole/}},
	year = {},
	note = {[Accessed 25-04-2025]},
}



@inproceedings{Ng2000ICML,
  author       = {Andrew Y. Ng and
                  Stuart Russell},
  title        = {Algorithms for Inverse Reinforcement Learning},
  booktitle    = {Proceedings of the Seventeenth International Conference on Machine
                  Learning {(ICML} 2000), Stanford University, Stanford, CA, USA, June
                  29 - July 2, 2000},
  pages        = {663--670},
  year         = {2000},
  url = {https://ai.stanford.edu/~ang/papers/icml00-irl.pdf}
}

@inproceedings{Ziebart2008AAAI,
author = {Ziebart, Brian D. and Maas, Andrew and Bagnell, J. Andrew and Dey, Anind K.},
title = {Maximum entropy inverse reinforcement learning},
year = {2008},
isbn = {9781577353683},
publisher = {AAAI Press},
abstract = {Recent research has shown the benefit of framing problems of imitation learning as solutions to Markov Decision Problems. This approach reduces learning to the problem of recovering a utility function that makes the behavior induced by a near-optimal policy closely mimic demonstrated behavior. In this work, we develop a probabilistic approach based on the principle of maximum entropy. Our approach provides a well-defined, globally normalized distribution over decision sequences, while providing the same performance guarantees as existing methods.We develop our technique in the context of modeling real-world navigation and driving behaviors where collected data is inherently noisy and imperfect. Our probabilistic approach enables modeling of route preferences as well as a powerful new approach to inferring destinations and routes based on partial trajectories.},
booktitle = {Proceedings of the 23rd National Conference on Artificial Intelligence - Volume 3},
pages = {1433–1438},
numpages = {6},
location = {Chicago, Illinois},
series = {AAAI'08},
url = {https://cdn.aaai.org/AAAI/2008/AAAI08-227.pdf}
}